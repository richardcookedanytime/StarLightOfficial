#!/usr/bin/env python3
"""
Starlight å¢å¼ºç‰¹æ€§æµ‹è¯•å¥—ä»¶
æµ‹è¯•è¯­æ³•ç³–ã€é€»è¾‘åŒ–æ‰©å±•å’Œå£°æ˜å¼ç¼–ç¨‹ç‰¹æ€§
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from compiler.lexer import Lexer
from compiler.enhanced_parser import EnhancedParser

def test_data_class_parsing():
    """æµ‹è¯•æ•°æ®ç±»è§£æ"""
    print("=== æµ‹è¯•æ•°æ®ç±»è§£æ ===")
    
    code = """
    data User(name: string, age: int) {
        fun isAdult(): boolean = age >= 18
    }
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        print(f"è¯æ³•åˆ†ææˆåŠŸï¼Œç”Ÿæˆ {len(tokens)} ä¸ª token")
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print(f"è¯­æ³•åˆ†ææˆåŠŸï¼Œç”Ÿæˆ {len(ast.statements)} ä¸ªè¯­å¥")
        
        if ast.statements:
            data_class = ast.statements[0]
            print(f"æ•°æ®ç±»å: {data_class.name}")
            print(f"å­—æ®µæ•°é‡: {len(data_class.fields)}")
            print(f"æ–¹æ³•æ•°é‡: {len(data_class.methods)}")
        
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®ç±»è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_rule_system():
    """æµ‹è¯•è§„åˆ™ç³»ç»Ÿ"""
    print("\n=== æµ‹è¯•è§„åˆ™ç³»ç»Ÿ ===")
    
    code = """
    rule adult(User.age >= 18) => User.canVote = true
    
    rule eligibility(user: User, product: Product) => {
        if (user.isAdult() && product.price <= user.budget) {
            user.canPurchase = true
        }
    }
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        
        print("Tokens:")
        for i, token in enumerate(tokens[:20]):  # æ˜¾ç¤ºå‰20ä¸ª
            print(f"  {i}: {token}")
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print("âœ… è§„åˆ™ç³»ç»Ÿè§£ææˆåŠŸ")
        
        if ast.statements:
            for stmt in ast.statements:
                print(f"  è§„åˆ™ç±»å‹: {type(stmt).__name__}")
        
        return True
    except Exception as e:
        print(f"âŒ è§„åˆ™ç³»ç»Ÿè§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_extension_functions():
    """æµ‹è¯•æ‰©å±•å‡½æ•°"""
    print("\n=== æµ‹è¯•æ‰©å±•å‡½æ•° ===")
    
    code = """
    extend String {
        fun isEmail(): boolean = this.contains("@")
        fun capitalize(): string = this.substring(0, 1).toUpperCase() + this.substring(1)
    }
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print("âœ… æ‰©å±•å‡½æ•°è§£ææˆåŠŸ")
        
        if ast.statements:
            extension = ast.statements[0]
            print(f"  æ‰©å±•ç±»å‹: {extension.target_type}")
            print(f"  å‡½æ•°æ•°é‡: {len(extension.functions)}")
        
        return True
    except Exception as e:
        print(f"âŒ æ‰©å±•å‡½æ•°è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_list_comprehension():
    """æµ‹è¯•åˆ—è¡¨æ¨å¯¼å¼"""
    print("\n=== æµ‹è¯•åˆ—è¡¨æ¨å¯¼å¼ ===")
    
    code = """
    val names = [user.name | for user in users if user.age > 18]
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        
        print("Tokens:")
        for i, token in enumerate(tokens):
            print(f"  {i}: {token}")
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print("âœ… åˆ—è¡¨æ¨å¯¼å¼è§£ææˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âŒ åˆ—è¡¨æ¨å¯¼å¼è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_transaction_block():
    """æµ‹è¯•äº‹åŠ¡å—"""
    print("\n=== æµ‹è¯•äº‹åŠ¡å— ===")
    
    code = """
    transaction {
        account1 -= 100
        account2 += 100
    }
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print("âœ… äº‹åŠ¡å—è§£ææˆåŠŸ")
        
        if ast.statements:
            transaction = ast.statements[0]
            print(f"  äº‹åŠ¡è¯­å¥æ•°é‡: {len(transaction.statements)}")
        
        return True
    except Exception as e:
        print(f"âŒ äº‹åŠ¡å—è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_version_and_features():
    """æµ‹è¯•ç‰ˆæœ¬å’Œç‰¹æ€§å£°æ˜"""
    print("\n=== æµ‹è¯•ç‰ˆæœ¬å’Œç‰¹æ€§å£°æ˜ ===")
    
    code = """
    @version("1.0")
    @feature("rules", enabled=true)
    @feature("comprehensions", enabled=false)
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        
        print("Tokens:")
        for i, token in enumerate(tokens):
            print(f"  {i}: {token}")
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print("âœ… ç‰ˆæœ¬å’Œç‰¹æ€§å£°æ˜è§£ææˆåŠŸ")
        
        if ast.statements:
            for stmt in ast.statements:
                print(f"  å£°æ˜ç±»å‹: {type(stmt).__name__}")
        
        return True
    except Exception as e:
        print(f"âŒ ç‰ˆæœ¬å’Œç‰¹æ€§å£°æ˜è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_pipe_expression():
    """æµ‹è¯•ç®¡é“è¡¨è¾¾å¼"""
    print("\n=== æµ‹è¯•ç®¡é“è¡¨è¾¾å¼ ===")
    
    code = """
    val result = users | filter { it.age > 18 } | map { it.name }
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print("âœ… ç®¡é“è¡¨è¾¾å¼è§£ææˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âŒ ç®¡é“è¡¨è¾¾å¼è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_complex_program():
    """æµ‹è¯•å¤æ‚ç¨‹åº"""
    print("\n=== æµ‹è¯•å¤æ‚ç¨‹åº ===")
    
    code = """
    @version("1.0")
    @feature("rules", enabled=true)
    
    data User(name: string, age: int) {
        fun isAdult(): boolean = age >= 18
    }
    
    rule adult(User.age >= 18) => User.canVote = true
    
    extend String {
        fun isEmail(): boolean = this.contains("@")
    }
    
    fun processUsers(users: List<User>): List<string> {
        return [user.name | for user in users if user.isAdult()]
    }
    
    fun main() {
        val users = listOf(User("Alice", 25), User("Bob", 17))
        val adultNames = processUsers(users)
        println(adultNames)
    }
    """
    
    try:
        lexer = Lexer(code)
        tokens = lexer.tokenize()
        
        parser = EnhancedParser(tokens)
        ast = parser.parse()
        print("âœ… å¤æ‚ç¨‹åºè§£ææˆåŠŸ")
        
        print(f"è§£æå‡º {len(ast.statements)} ä¸ªè¯­å¥:")
        for i, stmt in enumerate(ast.statements):
            print(f"  {i}: {type(stmt).__name__}")
            if hasattr(stmt, 'name'):
                print(f"    åç§°: {stmt.name}")
        
        return True
    except Exception as e:
        print(f"âŒ å¤æ‚ç¨‹åºè§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ Starlight å¢å¼ºç‰¹æ€§æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    tests = [
        test_data_class_parsing,
        test_rule_system,
        test_extension_functions,
        test_list_comprehension,
        test_transaction_block,
        test_version_and_features,
        test_pipe_expression,
        test_complex_program
    ]
    
    success_count = 0
    total_tests = len(tests)
    
    for test in tests:
        if test():
            success_count += 1
    
    print(f"\næµ‹è¯•ç»“æœ: {success_count}/{total_tests} é€šè¿‡")
    print("=" * 60)
    
    if success_count == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Starlight å¢å¼ºç‰¹æ€§å®ç°æˆåŠŸï¼")
    else:
        print(f"âš ï¸  æœ‰ {total_tests - success_count} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
